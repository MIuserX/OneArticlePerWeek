## 原文

https://severalnines.com/database-blog/postgresql-streaming-replication-deep-dive



## 翻译

​		高可用对于管理 PG 的管理员来说是必须的。这是个历久弥新的主题。这篇文章中，我们回顾一点 PG 内置的主从复制的历史，并深入理解流复制是如何工作的。

​		讨论主从复制时，还会讨论一些 WAL 的知识。所以，先来看一些 WAL 的知识。

### Write Ahead Log（WAL）

​		WAL 是保证数据完整性的标准方法，PG 默认是开启这个功能的。

​		WAL 是 PG 中的 REDO Log。但是，什么是 REDO Log 呢？

​		REDO Log 包含了数据库中的所有变更，被应用于主从复制、数据恢复、在线备份、时间点恢复(PITR)。任何没有应用到实际数据页的变化都可以通过 REDO Log 重放。

​		使用 WAL 可以明显地减小磁盘写地数量，因为只有 Log 文件需要被刷写到磁盘来保证事务被提交，而不是刷写每个被事务改变的数据文件。

​		一个 WAL Record 将会一点点的记录数据的变化。每个 WAL Record 将会被添加到一个 WAL 文件。插入位置是一个 LSN ，这个 LSN 在日志中的一个字节偏移，每个新 Record 增加一次。

​		WAL 文件被存储在数据目录下的 pg_xlog（PG 10是 pg_wal）目录，这些 WAL 文件默认每个 16MB（这个大小可以在构建服务器的时候用 `--with-wal-segsize`  改变）。每个日志文件拥有一个唯一的自增的名字，以格式：“0000001 00000000 00000000”。

​		pg_xlog（pg_wal）下的 WAL 文件的数量取决于 postgresql.conf 配置文件中的参数 `checkpoint_segments`（或者 `min_wal_size` 和 `max_wal_size` ，参数名字取决于 PG 版本）。

​		我们安装所有 PG 实例时都需要设置的一个参数是 `wal_level` 。这参数决定 WAL 中记录信息的详细程度。默认值是 `minimal` ，这仅仅只在 WAL 中记录发生 crash 或 immediate shutdown 进行恢复时所需的信息。

 		-- todo



### History Of Replication In PG

​		PG 实现的第一个主从复制方法(温备)(version 8.2，2006年)是基于 日志传送方法。

​		这意味着，WAL 记录是直接从一个数据库服务器移动到另一个服务器，然后应用。我们可以说这是个 PITR。

​		PostgreSQL 实现了基于文件的日志传送通过传送 WAL 记录一次一个文件（WAL Segment）。

​		这个主从复制实现有个缺点：如果在主库上存在一个主要错误，至今还没有被传送的事务将会丢失。所以有一个数据丢失窗口（你可以使用 `archive_timeout` 参数调整这个，这个参数可以设置低一点，几秒就行，但这样一个低的设置将会大体上增加文件传输需要的带宽）。

​		我们可以用下图表示这个方法：

![img](https://severalnines.com/sites/default/files/blog/node_5266/image1.jpg)



​		所以，在 PG 9.0（2010年），流复制产生了。

​		这个特性允许我们保持比基于日志传送更短的同步延迟，通过在运行时传送 WAL 记录(一个WAL文件由WAL记录组成)，在主库与一个或多个从库之间，不用等待 WAL 文件被填满。

​		在实践上，一个运行在从库上的叫做 WAL receiver 的进程，将会连接到主库，使用 TCP/IP 连接。在主库上，存在另一个进程，叫做 WAL Sender，负责发送 WAL 登记到从库当它们产生的时候。

​		流复制可以被表示为：

![img](https://severalnines.com/sites/default/files/blog/node_5266/image2.jpg)



​		通过看上图我们可以思考：WAL sender 与 WAL receiver 通信失败时，会发生什么？

​		当配置流复制的时候，我们可以开启 WAL 归档。

​		这个步骤实际上并不是强制的，但是对于强健的主从复制是极其重要的，因为避免主服务器循环旧的还没有被从库应用的 WAL 文件是必要的。如果发生了这种情况，我们需要重新创建流复制。

​		当配置带持续归档的流复制时，我们从一个备份开始，到达与主库的同步状态，我们需要应用备份之后发生的所有的ＷAL中的所有变化。在这个过程中，从库首先重放归档位置所有的WAL(通过调用restore_command)。restore_command 在到达最后一个WAL记录后会失败，所以在那之后，从库将会从 pg_wal(pg_xlog) 中查看是否存在变化(做这件事，是为了避免，在主库崩溃或有些变化没来得及同步并应用或没有归档时，发生数据丢失)。

　　如果在 pg_wal 中没找到请求的 WAL 记录，将会启动与主库之间的流复制通信。

　　无论何时流复制失效，都会从第一步开始，再次重放来自归档的记录。从归档或pg_wal中恢复、通过流复制，这个循环会一直持续，直到服务器停止或被触发器文件触发故障切换。

​		这个循环像下面这个图：

![img](https://severalnines.com/sites/default/files/blog/node_5266/image5.jpg)

​		

​		流复制默认是异步的，所以在一些给定的瞬间，我们可能有一些事务在主库已提交但没有复制到从库。这暗示了一些潜在的数据丢失。

​		然而这个延迟，在提交和变化在流复制中的影响被认为实际上很小（几毫秒），当然，这是在流复制服务器足够给力能抗住负载。

​		对于很小数据丢失都不能容忍的情况，PG 9.1 发布了同步流复制特性。

​		在同步流复制当中，每个写事务的提交将会等待，直到主从库都将提交写入到 WAL。

​		这个方法最小化了数据丢失的可能性，除非主从库同时宕机，数据丢失才可能发生。

​		这个配置明显的缺点是，我们需要为每个从库指定 `application_name` 在 recovery.conf  文件中的 `primary_conninfo` 配置项中：

```ini
primary_conninfo = '...application_name=slaveX'
```



​		我们也需要在主库的配置中参与同步流复制的从库的列表：

```ini
synchronous_standby_name='slaveX,slaveY'
```



​		我们可以设置一个或多个同步服务器，这个参数也指定如何从后备服务器列表中选出同步服务器的方法：FIRST or ANY。

​		当配置了流复制，它会启动并运行，我们需要监控它。



### Monitoring PG Replication

​		在主服务器上的 `pg_stat_replication` 视图，展示了大量相关的信息：

```sql
postgres=# SELECT * FROM pg_stat_replication;
 pid | usesysid | usename | application_name |  client_addr   | client_hostname | client_port |         backend_start         | backend_xmin |   state   | sent_lsn  | write_lsn | 
flush_lsn | replay_lsn | write_lag | flush_lag | replay_lag | sync_priority | sync_state 
-----+----------+---------+------------------+----------------+-----------------+-------------+-------------------------------+--------------+-----------+-----------+-----------+-
----------+------------+-----------+-----------+------------+---------------+------------
 994 |    16467 | repl    | walreceiver      | 192.168.100.42 |                 |       37646 | 2018-05-24 21:27:57.256242-03 |              | streaming | 0/50002C8 | 0/50002C8 | 
0/50002C8 | 0/50002C8  |           |           |            |             0 | async
(1 row)
```

​		让我们看看细节：

```
pid: WAL sender进程的进程ID
usesysid: 用来做流复制的用户的 OID
usename: 用来做流复制的用户的用户名
application_name: 连接到主库时用的名字
client_addr: 从库或流复制的IP地址
client_hostname: 从库的主机名
client_port: 从库与 WAL sender 通信用的端口号
backend_start: 连接到主库的开始时间
state: 当前的 WAL sender 的状态，例如：streaming
sent_lsn: 最后一个发送给从库的事务的 LSN
write_lsn: 最后一个从库写入磁盘的事务的 LSN
flush_lsn: 最后一个从库刷写到磁盘的事务的 LSN
replay_lsn: 最后一个从库刷写到磁盘的事务的 LSN
sync_priority: Priority of standby server being chosen as synchronous standby
sync_state: Sync State of standby (is it async or synchronous).
```



​		我们也可以在服务器上看到 WAL sender/receiver 进程在运行：

Sender(主节点)：

```bash
[root@postgres1 ~]# ps aux |grep postgres
postgres   833  0.0  1.6 392032 16532 ?        Ss   21:25   0:00 /usr/pgsql-10/bin/postmaster -D /var/lib/pgsql/10/data/
postgres   847  0.0  0.1 244844  1900 ?        Ss   21:25   0:00 postgres: logger process   
postgres   850  0.0  0.3 392032  3696 ?        Ss   21:25   0:00 postgres: checkpointer process   
postgres   851  0.0  0.3 392032  3180 ?        Ss   21:25   0:00 postgres: writer process   
postgres   852  0.0  0.6 392032  6340 ?        Ss   21:25   0:00 postgres: wal writer process   
postgres   853  0.0  0.3 392440  3052 ?        Ss   21:25   0:00 postgres: autovacuum launcher process   
postgres   854  0.0  0.2 247096  2172 ?        Ss   21:25   0:00 postgres: stats collector process   
postgres   855  0.0  0.2 392324  2504 ?        Ss   21:25   0:00 postgres: bgworker: logical replication launcher   
postgres   994  0.0  0.3 392440  3528 ?        Ss   21:27   0:00 postgres: wal sender process repl 192.168.100.42(37646) streaming 0/50002C8
```



Receiver(后备节点)：

```bash
[root@postgres2 ~]# ps aux |grep postgres
postgres   833  0.0  1.6 392032 16436 ?        Ss   21:27   0:00 /usr/pgsql-10/bin/postmaster -D /var/lib/pgsql/10/data/
postgres   848  0.0  0.1 244844  1908 ?        Ss   21:27   0:00 postgres: logger process   
postgres   849  0.0  0.2 392128  2580 ?        Ss   21:27   0:00 postgres: startup process   recovering 000000010000000000000005
postgres   851  0.0  0.3 392032  3472 ?        Ss   21:27   0:00 postgres: checkpointer process   
postgres   852  0.0  0.3 392032  3216 ?        Ss   21:27   0:00 postgres: writer process   
postgres   853  0.0  0.1 246964  1812 ?        Ss   21:27   0:00 postgres: stats collector process   
postgres   854  0.0  0.3 398860  3840 ?        Ss   21:27   0:05 postgres: wal receiver process   streaming 0/50002C8
```



​		一个检查我们的流复制是多新的方法是，检查主节点上生成的但没有在后备节点上应用的 WAL 的数量。

**Master：**

```sql
postgres=# SELECT pg_current_wal_lsn();
pg_current_wal_lsn
--------------------
0/50002C8
(1 row)
```

注意：这个函数在 PG 10 才有，以前的版本，需要用 `SELECT pg_current_xlog_location()`。



**Slave：**

```sql
postgres=# SELECT pg_last_wal_receive_lsn();
pg_last_wal_receive_lsn
-------------------------
0/50002C8
(1 row)

postgres=# SELECT pg_last_wal_replay_lsn();
pg_last_wal_replay_lsn
------------------------
0/50002C8
(1 row)
```

注意：这些函数从 PG 10 才有，以前的版本，你需要用：

```sql
SELECT pg_last_xlog_receive_location(); 
SELECT pg_last_xlog_replay_location();
```



​		我们可以使用下列的查询来延迟时间：

PG 10：

```sql
SELECT CASE WHEN pg_last_wal_receive_lsn() = pg_last_wal_replay_lsn()
THEN 0
ELSE EXTRACT (EPOCH FROM now() - pg_last_xact_replay_timestamp())
END AS log_delay;
```



PG 10 之前的版本：

```sql
SELECT CASE WHEN pg_last_xlog_receive_location() = pg_last_xlog_replay_location()
THEN 0
ELSE EXTRACT (EPOCH FROM now() - pg_last_xact_replay_timestamp())
END AS log_delay;
```



输出：

```sql
postgres=# SELECT CASE WHEN pg_last_wal_receive_lsn() = pg_last_wal_replay_lsn()
postgres-# THEN 0
postgres-# ELSE EXTRACT (EPOCH FROM now() - pg_last_xact_replay_timestamp())
postgres-# END AS log_delay;
log_delay
-----------
        0
(1 row)
```



​		流复制是基于：将 WAL 记录传送到从库并应用，基本上说：哪个文件里增加或修改了那些字节。作为结果，从库实际上在一点一点的复制主库。

​		有些已知的限制：

* 我们不能在不同版本或架构之间做流复制
* 我们不能在从库上修改数据
* 我们不能流复制的粒度



​		所以，因为上述的这些限制，PG 10 增加了逻辑复制。



### Logical Replication

​		逻辑复制也会使用 WAL 文件中的信息，但会将它解码为逻辑的数据变化。不用知道哪些字节被改变了，我们将确切地知道什么数据被插入到哪个表。

​		逻辑复制基于发布和订阅模型，存在一个或多个订阅者，订阅一个或多个发布或发布者节点，看起来像：

![img](https://severalnines.com/sites/default/files/blog/node_5266/image6.jpg)

​		逻辑复制使很多场景变得可能，像：只同步一些表 或者 将多个database合并到一个database里。
