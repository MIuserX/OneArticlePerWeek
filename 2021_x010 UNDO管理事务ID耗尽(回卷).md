## 原文

https://blog.crunchydata.com/blog/managing-transaction-id-wraparound-in-postgresql



## 译文

​		管理 PG 要理解的一个重要概念是：事务 IDs(TXID) ，并且如果不适当监控的话，事务 IDs 会被耗尽。然而，这篇文章实际上不讨论 TXID 耗尽的细节实际是什么。官方文档的 Routing Vacuuming 章节对于理解这个很重要，我将尝试将你引导到哪。

​		d



### Monitoring

​		大部分人最开始意识到这个问题，考虑他们监控的 TXID 回卷本身是个问题，但是技术上的 TXIDs 耗尽是真正的问题。PG 技术上是允许 TXID 值回卷的。然而，如果回卷点到达，TXIDs 接近耗尽，这才是回卷本身是需要关心的问题。

​		下面的 SQL 是我们在 Crunchy Data 在 PGmonitor 工具中提供的非常简单的报警点：

```sql
WITH max_age AS ( 
    SELECT 2000000000 as max_old_xid
        , setting AS autovacuum_freeze_max_age 
    FROM pg_catalog.pg_settings 
    WHERE name = 'autovacuum_freeze_max_age' )
, per_database_stats AS ( 
    SELECT datname
        , m.max_old_xid::int
        , m.autovacuum_freeze_max_age::int
        , age(d.datfrozenxid) AS oldest_current_xid 
    FROM pg_catalog.pg_database d 
    JOIN max_age m ON (true) 
    WHERE d.datallowconn ) 
SELECT max(oldest_current_xid) AS oldest_current_xid
    , max(ROUND(100*(oldest_current_xid/max_old_xid::float))) AS percent_towards_wraparound
    , max(ROUND(100*(oldest_current_xid/autovacuum_freeze_max_age::float))) AS percent_towards_emergency_autovac 
FROM per_database_stats
```



​		***percent_towards_wraparound*** 指标是非常重要的设置报警的指标。它使用 `age()` 函数来决定 TXID 值，如果他们实际上在耗尽点，要考虑他们，来看看是否回卷真是个问题。如果曾经到达过耗尽点，数据库会被强制关闭，会造成不确定的宕机时间，来修复问题。这个 SQL 有个小缓冲区，因为它检测的上界(实际上是2 billion) 比实际的造成耗尽的最大整数值小。但是这是足够近的，这个警告到达 100%，应该立刻按照这个行动。

​		***percent_towards_emergency_autovac*** 指标是一个额外的值，我们推荐有这个监控，特别是从没有过这个监控的系统（看 ）。这个查看 database 的到达了 `autovacuum_freeze_max_age` 最大 TXID 值。这是一个用户可调整的值，默认值是 200 million ，当任何表的最大 TXID 值到达它，一个更高优先级的 autovacuum 处理这个表。你可以识别这个特殊的 vacuum 会话，因为在 `pg_stat_activity` 中，它会被标记 ***(to prevent wraparound)***。它拥有更高的优先级，意思是，就算 autovacuum 被禁用或者 vacuum 被手动取消 它也会继续运行，它几乎可以重启。它会持有一些不同的、低层次的锁，所以它可能造成轻微的高连接数在哪些表上，具体取决于在紧急 vacuum 期间这些表被如何使用。如果你确实碰到了连接或锁问题，并且他们的原因就是紧急 vacuum，取消它来时你的其他事务继续是非常安全的。但要知道，它将会持续重启直到回卷 vacuum 完成成功，或者人工 vacuum 被运行。

​		对于事务非常多的 database，增加 `autovacuum_freeze_max_age` 可以避免紧急 vacuum 进行的很频繁，这是非常有益的。增加这个值的主要问题是也会增加 pg_xact 和 pg_commit_ts 目录的存储需要。再说一次，请阅读 Routine Vacuuming 文档，当你需要调整这个参数的时候。我通常将这个值设置为 1 billion ，没什么问题，但仅当我确认回卷是被监控着的，并且磁盘空间是足够的。

​		所以当任何一个这些报警离开的时候，你怎么修复它呢？



### Easy Fix

​		将最大 TXID 值降回去的最简单的方法是：对整个 DB Cluster 强制执行 vacuum 。并且做这件事的最好方法是 vacuumdb 整个二进制工具。

```bash
vacuumdb --all --freeze --jobs=2 --echo --analyze
```

​		`--all` 选项保证所有的 database 被 vacuum ，因为 TXID 是一个全局的值。 `--freeze` 选项保证一个更强力的 vacuum 被执行来保证尽可能多的元组被冻结。`--jobs=2` 允许更多的 vacuum 并行执行。这个应该设置为尽可能高，你的系统能处理过来的值，但要小心设置的过高会导致额外的 I/O 和更快的 WAL 生成速度（增加磁盘使用）。`--echo` 仅提供一些微小的反馈，所以你可以看到一些进度的描述。`--analyze` 保证统计信息被更新。如果时间是把 vacuum 运行完的关键点，这不会再被使用，并且运行为一个分离的步骤后续使用 `--analyze-only` 选项。



### Recent Freezing Benefits

​		`--freeze` 选项的另一个好处是对 I/O 和 WAL 生成量巨大减少，在未来的 vacuum 操作中。PG 9.6 发布了一个特性：允许 vacuum 可以跳过 所有元组都已冻结 的页。PG 11 在这个问题上的改进更多集中在索引上。所以如果你拥有大量的不再有写入的老表，这个优化正好适合它，这些表不需要以任何理由被 vacuum ，它是一个更便宜的操作。它也使 `percent_towards_emergency_autovac` 警告更少，作为一个关心事务，因为它不会相当多一个预期之外的活动峰值。所以一旦你将一切都调整好，你可以考虑这个报警一个低优先级的警告，或者删除它。仅仅关心回卷自身的监控。



### Per-Table Fix

​		如果你无法承受 DB Cluster 级别的 vacuum，仅仅想获取 TXID 年龄在控制之内，尽可能快地，这确实是可能地，但需要更多的步骤，相较于仅调用一个单二进制命令。这是无限地情况，如果你已经到达了回卷或被关库了。

```sql
SELECT datname
    , age(datfrozenxid)
    , current_setting('autovacuum_freeze_max_age') 
FROM pg_database 
ORDER BY 2 DESC;

  datname  |    age    | current_setting 
-----------+-----------+-----------------
 postgres  | 170604895 | 200000000
 mydb      | 169088197 | 200000000
 template0 | 142915024 | 200000000
 template1 | 142914999 | 200000000
```



​		这里你可以看到默认的 `postgres` database，和用户的 database，都是最立刻的关心，接近于紧急 vacuum。他们是感激的这里接近耗尽，但是你也会看见这里 年龄 接近 2.1 billion。接下来我们需要连接相关的 database 并看到表自己的状态。

```sql
postgres=# SELECT c.oid::regclass
    , age(c.relfrozenxid)
    , pg_size_pretty(pg_total_relation_size(c.oid)) 
FROM pg_class c
JOIN pg_namespace n on c.relnamespace = n.oid
WHERE relkind IN ('r', 't', 'm') 
AND n.nspname NOT IN ('pg_toast')
ORDER BY 2 DESC LIMIT 100;

                    oid                     |    age    | pg_size_pretty 
--------------------------------------------+-----------+----------------
 pg_proc                                    | 170606208 | 936 kB
 pg_description                             | 170606208 | 480 kB
 pg_depend                                  | 109192353 | 1336 kB
 pg_attribute                               | 109192353 | 728 kB
 pg_shdepend                                |  89774141 | 2976 MB
 pg_db_role_setting                         |  77594841 | 16 kB
 pg_tablespace                              |  77594841 | 72 kB
 pg_pltemplate                              |  77594841 | 56 kB
 pg_auth_members                            |  77594841 | 16 kB
 pg_authid                                  |  77594841 | 72 kB
[...]
```



​		这里，你可以看见仅存在一些表的年龄比较高，但在一个更贴近现实的表的例子，你可能看到结果，更接近于 100 行的限制，以更高的年龄。接下来，我们仅想要 vacuum 这些特殊的表，人工敲 vacuum 命令，不是一个大事。但是如果你有 100+，这就太冗长并且容易出错。所以我们可以使用字符串合并和一些 psql 命令来生成一些语句，并把他们放置在一个文件里，然后自动运行。

```sql
\t \o /tmp/vacuum.sql select 'vacuum freeze analyze verbose ' || oid::regclass || ';' from pg_class where relkind in ('r', 't', 'm') order by age(relfrozenxid) desc limit 100; \o \t \set ECHO all \i /tmp/vacuum.sql
```

​		我强烈推荐你看官方文档，这些命令做了什么，但基本上它做了这些：

* 关闭列的 header
* 发送所有的输出到 /tmp/vacuum.sql 文件
* 生成至多 100 个 VACUUM 语句对于每个从这个查询返回的表
* 关闭文件输出并开启列的 header
* 运行这个后输出每个命令
* 运行这些包含在 vacuum.sql 文件里的 vacuum 命令，一次一个



​		即使存在超过 100 个表需要被清理，我通常用 100 个批处理，给 I/O 和 WAL 生成的速度降降温。我通常尝试并获取最大的 XID 对于每个表，至少降到 `autovacuum_freeze_max_age` 的 50%，通常甚至会到 30%-40% ，如果这不会带来太多问题时。 



### Conclusion