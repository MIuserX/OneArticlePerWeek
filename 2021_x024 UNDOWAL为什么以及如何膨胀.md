# 原文

https://dzone.com/articles/postgresql-why-and-how-wal-bloats



# 翻译

## WAL. 一个简单介绍

对 PG 数据库的任何修改，首先被存储到 WAL，这样数据永远不会丢失。在这之后，内存页中（所谓的 "buffer cache"）的数据才会被修改并被标记为 “脏页” - 意味着它们需要被同步到磁盘。

存在一个 Checkpoint 进程，周期性地运行，它将所有的 “脏” 页写入磁盘。它也将位置保存到 WAL（叫做 **REDO point**），从开始到这个位置的数据库修改都已被同步到磁盘。

在 PG crash 时，它将会从 **REDO point** 开始顺序 replay WAL记录，来恢复状态。这样，恢复不再需要在这个点之前的 WAL 记录，但仍可能被主从复制需要 或者 被 PITR(Point In Time Recovery) 需要。

从这段描述中，一个超级工程师可能已经找出了，在实际生活中所有可能犯错的方式 :-)。但在现实生活中，一个人通常将以一种 reactive way：一个人首先需要在一个问题上跌倒。



## WAL 膨胀 #1

我们在每个 PG 实例上的监控工具将会发现 WAL 文件并收集它们的数量和总大小。

下面是一些奇怪的情况，WAL 总大小和 segment 数量增到大到了6倍：

>图

原因可能是什么呢？

做一次 checkpoint 之后 WAL 被认为不再被需要并被删除。这是我们为什么首先检查它的原因。PG 有个特别的系统视图叫做 `pg_stat_bgwriter` ，包含了一些关于 checkpoint 的信息：

* **checkpoints_timed** - 由于距离前一个 checkpoint 
* **checkpoints_req** - 



## WAL 膨胀 #2 - 归档

能让你恢复到过去的任何时间点的备份称得上是好备份。

如果 “某人”（当然，不是你！）在主库上执行了下面的命令：

```sql
DELETE FROM very_important_tbl;
```

你最好有方法将数据库恢复到刚好在这个事务之前。这叫做 PITR (Point-In-Time-Recovery)。

在 PG 中，你需要周期性地做 全量备份，并启用 WAL 归档。对于这个，有个特殊的配置参数 - `archive_command` 和一个特别的进程 `postgres: archiver process` 。周期性地按你的选择运行这个命令，如果这个命令没有返回错误，就会删除相应的 WAL segment 文件。如果归档时发生了错误，这在广泛的使用云架构时变得普遍（是的，我在看着你，AWS S3），PG 将会不断重试，直到成功。这会导致磁盘上堆积大量的 WAL segments 文件，并逐渐耗尽磁盘空间。

下面是一个时间短的 WAL 归档的统计图：

> 图

你可以从 `pg_stat_archiver` 视图中看到这些统计。

任何监控系统采集不同的指标，在服务器架构上。并且不仅仅是图表，也可以在它们上设置报警，并用来改进架构变得更有弹性。

问题是大部分广泛使用的软件，没有被设计为具有深入的可测量性。这是为什么设置监控系统能及时为你展示你所需要的一切的很困难的原因。

很多至关重要的指标很难收集。它通常不通过某些系统视图，所以你可以通过 `select supa_useful_stat from cool_stat_view` 。当开发 okmeter 监控程序的时候，我们深入发觉了有意义和细节的指标，所以当你需要的时候，你就能获取它们。

这对 WAL 和 归档也是的 - 我们不仅仅从 `pg_stat_archiver` 收集失败次数 和 磁盘上的 WAL 大小，还有 okmeter.io，你会有指标展示磁盘上仅仅为了归档而存在的 WAL 的数量。下面图里展示了如何归档失败是指标的样子：

> 图

我们的监控系统 - okmeter - 不仅仅自动收集这些指标，也会在归档失败时发出告警。



## Replication

众所周知，PG 使用流复制，通过持续传输与重放 WAL segment 文件 到/在 流复制从库上。

对于有些从库无法立即获取所有所需要的 WAL 文件时，主库会存放这些 WAL 文件。配置参数 `wal_keep_segments` 控制主库上会存放多少 WAL 。但是如果从库卡住并且延迟超过保存的 WAL ，WAL 文件会被删除，这会导致这个从库无法连接上主库来持续它的流复制，使得它无法使用。要让这个从库继续主从复制，需要从一个基础备份重做。

为了更深入的控制和缓解这个问题，PG 9.4 开始有了个特别的算法：复制槽。



## WAL 膨胀 #3 - 复制槽

当这些被使用的时候，当设置了主从复制 并且 一个复制槽从从库获取过一个连接至少一次（你可以认为这是 “被激活了”），这时如果从库落后了，主库会保留所有需要的 WAL 文件直到从库连接并达到当前状态。

或者，如果从库永远下线了，主库将会永远保留这些文件，导致所有磁盘都被这个消耗。

> 一个被遗忘的(一个没有监控的)复制槽，不仅仅会导致 WAL 日志膨胀，也可能导致数据库宕机。

幸运的是，通过系统视图 `pg_replication_slots` 监控它非常简单。

我们建议你不仅仅监控复制槽状态，也要跟踪为了流复制而存在的 WAL 大小，像我们那样，例如，这里：

> 图

它不仅仅展示了 WAL 的总膨胀，并且有细节的视图，你可以看到具体是哪个复制槽造成了问题：

> 图

当我们看到具体是哪个，我们就能决定怎么处理。无论是尝试修复这些复制，或者，直接删除复制槽。

这些是 WAL 膨胀最常见的原因，虽然我不确定还有没有其他的原因。对于数据库不间断服务，监控它非常必要。

我们推荐你设置这样一个监控，或者使用一个 SaaS 服务。
